{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6 predict_BERT_TF_Hub.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jVr2f1fh1nvg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731381019,"user_tz":-480,"elapsed":19757,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"49db4ce3-977f-4f4c-e246-30f609b0f1df"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"blhm1NYaeCR2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731383761,"user_tz":-480,"elapsed":952,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"e165da90-3310-4c39-83af-212606cfc754"},"source":["%tensorflow_version 1.X"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.X`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eg3v98dleTma","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731392525,"user_tz":-480,"elapsed":5368,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"8cc10ab2-218a-441f-9971-fe22338f643c"},"source":["#Installing BERT module\n","!pip install bert-tensorflow==1.0.1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow==1.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lGTplMLyYiCg"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"1NhdWxqnYuFQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731397782,"user_tz":-480,"elapsed":7602,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"458ced81-15f9-4fed-d630-9acf74467170"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","print(\"tensorflow version : \", tf.__version__)\n","print(\"tensorflow_hub version : \", hub.__version__)\n","\n","#Importing BERT modules\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensorflow version :  1.15.2\n","tensorflow_hub version :  0.10.0\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EcbzuCFodj6B"},"source":["## Set parameters"]},{"cell_type":"code","metadata":{"id":"CZLO57pxYs-g","executionInfo":{"status":"ok","timestamp":1609731424213,"user_tz":-480,"elapsed":845,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["# Set the output directory for saving model file\n","OUTPUT_DIR = 'model'\n","\n","label_list = [0, 1, 2]\n","# We will also set a sequence length which will be the length of the input features.\n","MAX_SEQ_LENGTH = 256 #128"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUwuD-1TdVlE"},"source":["## Prepare the model"]},{"cell_type":"markdown","metadata":{"id":"URf7PU7Vgids"},"source":["The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts.  \n","check the model list here: https://tfhub.dev/s?network-architecture=transformer&publisher=google"]},{"cell_type":"code","metadata":{"id":"7l_MmKgWbzLp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731431836,"user_tz":-480,"elapsed":4600,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"8381f199-14cd-418b-fd6e-c63a1d4f8848"},"source":["# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_chinese_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"D4-Cgnp4hk5w"},"source":["## Create multi-class classifier model"]},{"cell_type":"code","metadata":{"id":"nQh5xVrEg1Bb","executionInfo":{"status":"ok","timestamp":1609731434476,"user_tz":-480,"elapsed":699,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5MeIBGig1FP","executionInfo":{"status":"ok","timestamp":1609731438699,"user_tz":-480,"elapsed":885,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["#A function that adapts our model to work for training, evaluation, and prediction.\n","\n","# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        \n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","            }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gasIwk_Dg0-8","executionInfo":{"status":"ok","timestamp":1609731442896,"user_tz":-480,"elapsed":912,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 300\n","SAVE_SUMMARY_STEPS = 100\n","\n","# Compute train and warmup steps from batch size\n","num_train_steps = 80\n","num_warmup_steps = 8\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0j3b9lthwTA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731445216,"user_tz":-480,"elapsed":885,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"ea40f37b-eb5b-40f9-d5cd-4f9bbe49072b"},"source":["#Initializing the model and the estimator\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":10,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16e6ac59b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16e6ac59b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4ki3_iSU4rmU"},"source":["## Load the trained checkpoint"]},{"cell_type":"code","metadata":{"id":"DLn2GZX14wKK","executionInfo":{"status":"ok","timestamp":1609731554474,"user_tz":-480,"elapsed":41758,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["!cp drive/My\\ Drive/Colab\\ data/BERT/BERTmodel.tar.gz .\n","!tar -xf BERTmodel.tar.gz"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFO60WlUjD_C"},"source":["## Predict function"]},{"cell_type":"code","metadata":{"id":"tq5ku4VsjEtJ","executionInfo":{"status":"ok","timestamp":1609731852343,"user_tz":-480,"elapsed":1466,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}}},"source":["# low medium high\n","# 0 1 2\n","# A method to get predictions\n","def getPrediction(in_sentences):\n","  #A list to map the actual labels to the predictions\n","  labels = ['low', 'high', 'None']\n","\n","  #Transforming the test data into BERT accepted form\n","  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n","  \n","  #Creating input features for Test data\n","  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","  #Predicting the classes \n","  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","  predictions = estimator.predict(predict_input_fn)\n","  return [(sentence, prediction['probabilities'],prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hph_tmGR7MOH"},"source":["## Predict the csv file (multiple inputs)"]},{"cell_type":"code","metadata":{"id":"ojbZCkrZ7Ovr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609732240926,"user_tz":-480,"elapsed":977,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"59ff0290-ea65-41f3-ef16-163d2bccd098"},"source":["#multiple inputs\n","#用記事本打開csv文件，另存為设置編碼為utf-8\n","test_data_source = \"data/test_data_temp.csv\"\n","test_data_df = pd.read_csv(test_data_source, encoding='utf8', delimiter=',')\n","print(test_data_df.head())\n","\n","print(\"\\n\")\n","test_data = list(test_data_df['Description'])\n","print(test_data[0])"],"execution_count":26,"outputs":[{"output_type":"stream","text":["   ID                                        Description  Class\n","0   0  - - - - - - - - - - - - - -附錄：【發文與推文罰則】- - - -...    NaN\n","1   1                     --　　　　　　　　　　　　　　　　　　　　　    　--    NaN\n","2   2  版友們有哪些討厭的副作用呢？今天去運動途中哭了因為副作用讓我覺得沒辦法掌控自己的身體很痛苦 ...    NaN\n","3   3  「我會在，你放心。我們就慢慢把環境適應。」治療的最後，L說著，想要安撫我下週工作室搬遷的焦慮...    NaN\n","4   4  其實我也不知道在焦慮甚麼也許是不想有人來管吧?本來是社區自聘的管理員6/1起外包給保全公司我...    NaN\n","\n","\n","- - - - - - - - - - - - - -附錄：【發文與推文罰則】- - - - - - - - - - - - - -第一條　凡未分類、自創分類、未滿20字（不含標點符號）之文章，　　　　含有自殺、自殘、OD相關內容，未在標題加註「有雷」或「雷」者，　　　　初犯者板主將直接刪除文章，不另外公告或通知。　　　　其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第二條　發文內容或推文大部分內容，違反中華民國法律者，　　　　初犯者板主將直接刪除文章並並水桶三日，不另外公告或通知。　　　　其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第三條　尋死文、自殺文、自殘文、OD文、藥物徵求買賣文等違規文章，　　　　除自殺文暫保留二日以便板友關心追蹤外，其餘文直接刪除並水桶三日。　　　　解除水桶之後其發文仍未遵循板規者，其發文劣退並水桶一個月。　　　　水桶後無論自行發文或在其他板友文章內推文再犯者皆永久水桶。第四條　本板對人身攻擊定義，不論是主動攻擊他人或因對他人言論不滿而回擊者，　　　　只要構成人身攻擊之事實，即視為違規，依程度輕重照板規懲處。　　　　此外，意見不合與人身攻擊間有很大的落差，　　　　請發文推文者勿因他人持反對意見，就任意指責對方人身攻擊，　　　　如經板主認定檢舉人有濫訴之嫌，得以不回應其檢舉。　　　　　　　認定標準為：該字詞足以引起本板板友普遍性之不悅，並達到動怒的程度。　　　　例：「你根本不是憂鬱症吧！」、「會生病是你活該」等　　　　普通人身攻擊文劣退處理，並水桶一週；於推文中普通人身攻擊者水桶一週。　　　　其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。　　　　　　　認定標準為：該字詞足以引起一般使用者普遍性之不悅，並達到動怒的程度。　　　　例：「你去死」、「吃屎吧你」等　　　　惡意人身攻擊文劣退處理，並水桶二週；於推文中惡意人身攻擊者水桶二週。　　　　其後發文或推文仍未改善者劣退水桶二個月。三犯永久水桶。　　　　　　　認定標準為：可能觸犯刑法公然侮辱罪，含三字經、不雅形容詞等用詞。　　　　例：「幹」、「醜」、「賤」、「智障」、「白痴」、「腦殘」、「丁丁」等。　　　　公然侮辱罪需針對特定人士辱罵才能成立，用以上詞彙評論事件，　　　　或是該文章、推文中無法推斷出發表者有針對特定人物，不構成公然侮辱罪。　　　　但若有符合上述普通、惡意的人身攻擊標準，仍比照板規處理。　　　　違法人身攻擊文劣退並水桶一個月；於推文中違法人身攻擊者水桶一個月。　　　　其後發文或推文仍未改善者劣退水桶三個月。三犯永久水桶。　　　第五條　私人糾紛請私下處理，如對方已有騷擾之嫌，請至Violation板依規定檢舉。　　　　針對各種私人糾紛及狀況，本板採用以下規律進行處理：　　　　　　　板內糾紛之當事人於憂鬱板上發文或推文，且引起糾紛之雙方或多方，　　　　已在發文或推文中，出現人身攻擊、謾罵、挑釁、嘲諷、歧視等文字，　　　　板內糾紛文劣退處理並水桶一週；於推文中引發或回覆糾紛者水桶二週。　　　　其後發文仍未改善者，再劣退並水桶一個月；推文仍未改善者，水桶二個月。　　　　水桶後發文依然如故者水桶永久水桶、推文累犯超過一次者永久水桶。　　　　　　　跨板糾紛指將其他板面之糾紛事務帶入本板發文或推文中並再次引發糾紛，　　　　造成本板混亂，且回推文已出現人身攻擊、謾罵、挑釁、嘲諷、歧視等文字；　　　　跨板糾紛文劣退處理並水桶二週；於推文中引發或回覆糾紛者水桶一個月　　　　　　　1.若該私人糾紛已造成大量板友之不悅，甚至影響到板友情緒或加重病情時，　　　　　只要有超過15人公開以回推文表示受到影響，超過2人依規定向板主檢舉，　　　　　不論原文文章內容，或被指名之使用者推文內容是否達到違規程度，　　　　　該發文／推文者即被認定為在憂鬱版鬧板的使用者，改以鬧板文處置。　　　　　且依情節嚴重程度懲處，必要時板主有權發起投票裁決。　　　　2.若私人糾紛之當事人，或其它回文推文參與討論之板友，　　　　　因該糾紛遭懲處後，直接在板面上向板主及板友放話，　　　　　或以站內信、水球等方式，向板主挑釁，揚言將於本板板面，　　　　　以任何形式擴大紛爭，或欲報復與其意見不合者，　　　　　直接視為蓄意破壞板面秩序之惡意鬧板者，永久水桶。　　　　　必要時，板主得將相關站內信、水球，做為板務溝通證據，　　　　　呈送給本組小組長，以特殊案件處理。　　　　3.另為顧慮以多重ID持有者蓄意鑽取本規定漏洞，　　　　　若是使用多重ID發表私人糾紛類型文，經站務相關方面查證後，　　　　　不論糾紛文造成的傷害程度輕重，該使用者及其多重ID均永久水桶。　　　　　若因浮動ip造成無法判定該id是否為分身id者，該id暫處水桶，　　　　　且待板主群於群組板申請多重ID移送ID_Multi後，　　　　　由PTT站方判定是否為多重ID再解除水桶並依照憂鬱板板規處理。　　　　　　　1.私人糾紛之當事人於板面上發文或推文，　　　　　但引起糾紛者尚能維持理性和平之討論，未發生違反板規情事。　　　　2.該糾紛雖已有其它非當事人加入討論，但參與者僅是提出解決糾紛之建議，　　　　　並未進一步擴大糾紛，討論串中也未出現違規情結者。：第六條　鬧板文劣退處理，於推文中鬧板者水桶一週；　　　　其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第七條　注音文將直接刪除文章並退回發文者信箱，不事先警告，也不另行公告。　　　　其後發文仍未改善者再刪文，並視為不尊重板規、水桶一個月。　　　　累犯超過三次者，劣退處理；劣退後依然如故者，永久水桶。第七條　非公益形態、能造成他人利益之廣告文直接劣退，外加永久水桶。第八條　誤用板主專用分類標題[公告]者，一律視為惡意鬧板，永久水桶。- - - - - - - - - - - 附錄：【違規文章及違規推文說明】- - - - - - - - - - - -　　１、廣告文：文章內容或推文有廣告嫌疑，或該文明顯可增加發文者利益者均屬廣告文。２、自殺文：文章內容或推文與自殺有關者，含自殺方法討論、慫恿他人自殺。　　　　　　勸導板友勿自殺者，或純粹討論生死意義者不在此限。３、尋死文：文章內容或推文有尋死意圖者，如出現「我要死」、「我要跳樓」等文字，　　　　　　有尋死之想法而向板友求助者，討論如何解決尋死意圖者不在此限。４、藥物文：文章內容或推文中徵求、買賣藥物或提供、詢問非正當藥物取得方法等等。　　　　　　各項藥物問題請詢問醫生，並遵照醫囑服用藥物。５、ＯＤ文：文章內容或推文與OD有關者。　　　　　　對OD行為感到後悔，勸導板友勿OD者不在此限；　　　　　　但嚴禁在文章中提及OD的藥品名稱及數量，違者依OD文處置。６、自殘文：文章內容或推文與自殘有關者，含自殘意圖、自殘討論、自殘感想。　　　　　　對自殘行為感到後悔，勸導板友勿自殘者不在此限。　　　　　　但嚴禁在文章中詳述或提及詳細的自殘方法及過程，違者依自殘文處置。７、攻擊文：文章內容或推文中公佈私人資料或各類型人身攻擊等等。　　　　　　於推文中人身攻擊者，有指名則視為攻擊被指名之對象，　　　　　　未指名者則視為攻擊該文章作者。　　　　　　板友發洩情緒並無不可，但請將相關人物名稱與不雅文字做隱藏處理，　　　　　　並請避免使用具有污辱性之詞句，以免觸犯法律。　　　　　　本板將人身攻擊分為「普通」、「惡意」、「違法」等三種程度，　　　　　　依嚴重程度不同，有不同等級的懲處，請詳見本板規之罰則內容。８、鬧板文：除版主能及時認定為刻意洗版、鬧版的文章之外，　　　　　　若有文章或推文造成大量板友之不悅，甚至影響到板友情緒或加重病情時，　　　　　　只要有超過15人公開以回推文表示受到影響，超過2人依規定向板主檢舉，　　　　　　不論原文文章內容，或被指名之使用者推文內容是否達到違規程度，　　　　　　該發文／推文者即被認定為在憂鬱版鬧板的使用者，　　　　　　將依情節嚴重程度懲處，必要時板主有權發起投票裁決。　　　　　　　９、注音文：文章內容有注音符號者，例：我ㄉ、好ㄇ、ㄍㄍ等，　　　　　　或文章內容中有火星文者，例：可ｉ、泥棉等皆算注音火星文；　　　　　　若有無法以中文表達的音，如ㄍㄧㄥ、ㄎㄎ等，　　　　　　或必須以諧音字表達的字詞，如：逼埃、撒比速等，　　　　　　以上比較特殊的狀況不在此限。--如果因為我的言論而對prozac版產生恐懼的朋友 先跟你們說對不起我身為一個邊緣性人格障礙的患者 總是常常會不由自主的歇斯底里起來請原諒我的措辭太過於嚴厲/偏激/惡霸/兇殘..(請自行帶入任何負面字眼)但是請記得我的名字 因為我好喜歡我是Prozac版最愛罵人的雞巴版主     --\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wazCPs8v77jG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731749367,"user_tz":-480,"elapsed":17946,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"f25b000e-3bad-49d6-b2ac-fe44b1206361"},"source":["test_results = getPrediction(test_data)\n","print(\"#\"*50)\n","print(test_results[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 11\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 11\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - - - - - - - - - - - - - - 附 錄 ： 【 發 文 與 推 文 罰 則 】 - - - - - - - - - - - - - - 第 一 條 凡 未 分 類 、 自 創 分 類 、 未 滿 20 字 （ 不 含 標 點 符 號 ） 之 文 章 ， 含 有 自 殺 、 自 殘 、 [UNK] 相 關 內 容 ， 未 在 標 題 加 註 「 有 雷 」 或 「 雷 」 者 ， 初 犯 者 板 主 將 直 接 刪 除 文 章 ， 不 另 外 公 告 或 通 知 。 其 後 發 文 或 推 文 仍 未 改 善 者 劣 退 水 桶 一 個 月 。 三 犯 永 久 水 桶 。 第 二 條 發 文 內 容 或 推 文 大 部 分 內 容 ， 違 反 中 華 民 國 法 律 者 ， 初 犯 者 板 主 將 直 接 刪 除 文 章 並 並 水 桶 三 日 ， 不 另 外 公 告 或 通 知 。 其 後 發 文 或 推 文 仍 未 改 善 者 劣 退 水 桶 一 個 月 。 三 犯 永 久 水 桶 。 第 三 條 尋 死 文 、 自 殺 文 、 自 殘 文 、 [UNK] 文 、 藥 物 徵 求 買 賣 文 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - - - - - - - - - - - - - - 附 錄 ： 【 發 文 與 推 文 罰 則 】 - - - - - - - - - - - - - - 第 一 條 凡 未 分 類 、 自 創 分 類 、 未 滿 20 字 （ 不 含 標 點 符 號 ） 之 文 章 ， 含 有 自 殺 、 自 殘 、 [UNK] 相 關 內 容 ， 未 在 標 題 加 註 「 有 雷 」 或 「 雷 」 者 ， 初 犯 者 板 主 將 直 接 刪 除 文 章 ， 不 另 外 公 告 或 通 知 。 其 後 發 文 或 推 文 仍 未 改 善 者 劣 退 水 桶 一 個 月 。 三 犯 永 久 水 桶 。 第 二 條 發 文 內 容 或 推 文 大 部 分 內 容 ， 違 反 中 華 民 國 法 律 者 ， 初 犯 者 板 主 將 直 接 刪 除 文 章 並 並 水 桶 三 日 ， 不 另 外 公 告 或 通 知 。 其 後 發 文 或 推 文 仍 未 改 善 者 劣 退 水 桶 一 個 月 。 三 犯 永 久 水 桶 。 第 三 條 尋 死 文 、 自 殺 文 、 自 殘 文 、 [UNK] 文 、 藥 物 徵 求 買 賣 文 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 118 118 118 118 118 118 118 118 118 118 118 118 118 118 7353 7087 8038 523 4634 3152 5645 2972 3152 5391 1179 524 118 118 118 118 118 118 118 118 118 118 118 118 118 118 5018 671 3454 1127 3313 1146 7546 510 5632 1201 1146 7546 510 3313 4021 8113 2099 8020 679 1419 3560 7953 5016 5998 8021 722 3152 4995 8024 1419 3300 5632 3669 510 5632 3659 510 100 4685 7302 1058 2159 8024 3313 1762 3560 7539 1217 6263 519 3300 7440 520 2772 519 7440 520 5442 8024 1159 4306 5442 3352 712 2200 4684 2970 1165 7370 3152 4995 8024 679 1369 1912 1062 1440 2772 6858 4761 511 1071 2527 4634 3152 2772 2972 3152 793 3313 3121 1587 5442 1219 6842 3717 3446 671 943 3299 511 676 4306 3719 719 3717 3446 511 5018 753 3454 4634 3152 1058 2159 2772 2972 3152 1920 6956 1146 1058 2159 8024 6889 1353 704 5836 3696 1751 3791 2526 5442 8024 1159 4306 5442 3352 712 2200 4684 2970 1165 7370 3152 4995 699 699 3717 3446 676 3189 8024 679 1369 1912 1062 1440 2772 6858 4761 511 1071 2527 4634 3152 2772 2972 3152 793 3313 3121 1587 5442 1219 6842 3717 3446 671 943 3299 511 676 4306 3719 719 3717 3446 511 5018 676 3454 2204 3647 3152 510 5632 3669 3152 510 5632 3659 3152 510 100 3152 510 5973 4289 2547 3724 6525 6546 3152 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 118 118 118 118 118 118 118 118 118 118 118 118 118 118 7353 7087 8038 523 4634 3152 5645 2972 3152 5391 1179 524 118 118 118 118 118 118 118 118 118 118 118 118 118 118 5018 671 3454 1127 3313 1146 7546 510 5632 1201 1146 7546 510 3313 4021 8113 2099 8020 679 1419 3560 7953 5016 5998 8021 722 3152 4995 8024 1419 3300 5632 3669 510 5632 3659 510 100 4685 7302 1058 2159 8024 3313 1762 3560 7539 1217 6263 519 3300 7440 520 2772 519 7440 520 5442 8024 1159 4306 5442 3352 712 2200 4684 2970 1165 7370 3152 4995 8024 679 1369 1912 1062 1440 2772 6858 4761 511 1071 2527 4634 3152 2772 2972 3152 793 3313 3121 1587 5442 1219 6842 3717 3446 671 943 3299 511 676 4306 3719 719 3717 3446 511 5018 753 3454 4634 3152 1058 2159 2772 2972 3152 1920 6956 1146 1058 2159 8024 6889 1353 704 5836 3696 1751 3791 2526 5442 8024 1159 4306 5442 3352 712 2200 4684 2970 1165 7370 3152 4995 699 699 3717 3446 676 3189 8024 679 1369 1912 1062 1440 2772 6858 4761 511 1071 2527 4634 3152 2772 2972 3152 793 3313 3121 1587 5442 1219 6842 3717 3446 671 943 3299 511 676 4306 3719 719 3717 3446 511 5018 676 3454 2204 3647 3152 510 5632 3669 3152 510 5632 3659 3152 510 100 3152 510 5973 4289 2547 3724 6525 6546 3152 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - - - - [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] - - - - [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 118 118 118 118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 118 118 118 118 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 版 友 們 有 哪 些 討 厭 的 副 作 用 呢 ？ 今 天 去 運 動 途 中 哭 了 因 為 副 作 用 讓 我 覺 得 沒 辦 法 掌 控 自 己 的 身 體 很 痛 苦 悲 從 中 來 運 動 暫 時 可 以 忘 掉 但 一 想 到 眼 淚 就 冒 出 眼 眶 好 痛 苦 但 不 能 不 吃 藥 希 望 自 己 不 要 被 藥 物 綁 住 但 現 階 段 我 不 能 不 吃 藥 . . . 好 沮 喪 感 覺 連 掌 控 權 都 沒 有 「 妳 還 好 嗎 ？ 」 人 們 問 。 「 我 不 好 。 」 她 們 就 會 一 臉 尷 尬 的 沈 默 了 不 然 你 們 希 冀 什 麼 答 案 啊 ？ - - + 1 可 以 問 但 是 不 要 對 方 回 答 負 面 的 就 不 開 心 的 沈 默 . . . [UNK] 或 是 無 語 問 蒼 天 嗯 嗯 不 要 期 待 一 個 很 正 面 的 回 答 不 要 去 預 設 一 個 美 好 的 回 應 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 版 友 們 有 哪 些 討 厭 的 副 作 用 呢 ？ 今 天 去 運 動 途 中 哭 了 因 為 副 作 用 讓 我 覺 得 沒 辦 法 掌 控 自 己 的 身 體 很 痛 苦 悲 從 中 來 運 動 暫 時 可 以 忘 掉 但 一 想 到 眼 淚 就 冒 出 眼 眶 好 痛 苦 但 不 能 不 吃 藥 希 望 自 己 不 要 被 藥 物 綁 住 但 現 階 段 我 不 能 不 吃 藥 . . . 好 沮 喪 感 覺 連 掌 控 權 都 沒 有 「 妳 還 好 嗎 ？ 」 人 們 問 。 「 我 不 好 。 」 她 們 就 會 一 臉 尷 尬 的 沈 默 了 不 然 你 們 希 冀 什 麼 答 案 啊 ？ - - + 1 可 以 問 但 是 不 要 對 方 回 答 負 面 的 就 不 開 心 的 沈 默 . . . [UNK] 或 是 無 語 問 蒼 天 嗯 嗯 不 要 期 待 一 個 很 正 面 的 回 答 不 要 去 預 設 一 個 美 好 的 回 應 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4276 1351 947 3300 1525 763 6245 1339 4638 1199 868 4500 1450 8043 791 1921 1343 6880 1240 6854 704 1526 749 1728 4158 1199 868 4500 6366 2769 6221 2533 3760 6794 3791 2958 2971 5632 2346 4638 6716 7768 2523 4578 5736 2650 2537 704 889 6880 1240 3271 3229 1377 809 2563 2957 852 671 2682 1168 4706 3907 2218 1088 1139 4706 4702 1962 4578 5736 852 679 5543 679 1391 5973 2361 3307 5632 2346 679 6206 6158 5973 4289 5192 857 852 4412 7389 3667 2769 679 5543 679 1391 5973 119 119 119 1962 3775 1603 2697 6221 6865 2958 2971 3609 6963 3760 3300 519 1986 6917 1962 1621 8043 520 782 947 1558 511 519 2769 679 1962 511 520 1961 947 2218 3298 671 5622 2220 2217 4638 3755 7949 749 679 4197 872 947 2361 1078 784 7938 5031 3428 1557 8043 118 118 116 122 1377 809 1558 852 3221 679 6206 2205 3175 1726 5031 6511 7481 4638 2218 679 7274 2552 4638 3755 7949 119 119 119 100 2772 3221 4192 6295 1558 5895 1921 1638 1638 679 6206 3309 2521 671 943 2523 3633 7481 4638 1726 5031 679 6206 1343 7521 6257 671 943 5401 1962 4638 1726 2746 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 4276 1351 947 3300 1525 763 6245 1339 4638 1199 868 4500 1450 8043 791 1921 1343 6880 1240 6854 704 1526 749 1728 4158 1199 868 4500 6366 2769 6221 2533 3760 6794 3791 2958 2971 5632 2346 4638 6716 7768 2523 4578 5736 2650 2537 704 889 6880 1240 3271 3229 1377 809 2563 2957 852 671 2682 1168 4706 3907 2218 1088 1139 4706 4702 1962 4578 5736 852 679 5543 679 1391 5973 2361 3307 5632 2346 679 6206 6158 5973 4289 5192 857 852 4412 7389 3667 2769 679 5543 679 1391 5973 119 119 119 1962 3775 1603 2697 6221 6865 2958 2971 3609 6963 3760 3300 519 1986 6917 1962 1621 8043 520 782 947 1558 511 519 2769 679 1962 511 520 1961 947 2218 3298 671 5622 2220 2217 4638 3755 7949 749 679 4197 872 947 2361 1078 784 7938 5031 3428 1557 8043 118 118 116 122 1377 809 1558 852 3221 679 6206 2205 3175 1726 5031 6511 7481 4638 2218 679 7274 2552 4638 3755 7949 119 119 119 100 2772 3221 4192 6295 1558 5895 1921 1638 1638 679 6206 3309 2521 671 943 2523 3633 7481 4638 1726 5031 679 6206 1343 7521 6257 671 943 5401 1962 4638 1726 2746 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 「 我 會 在 ， 你 放 心 。 我 們 就 慢 慢 把 環 境 適 應 。 」 治 療 的 最 後 ， [UNK] 說 著 ， 想 要 安 撫 我 下 週 工 作 室 搬 遷 的 焦 慮 。 當 下 覺 得 很 溫 暖 ， 很 放 心 地 微 笑 了 ， 可 是 我 現 在 卻 快 要 被 恐 懼 焦 慮 淹 沒 ， 因 為 [UNK] 也 給 過 我 太 多 承 諾 。 我 很 清 楚 [UNK] 和 [UNK] 是 截 然 不 同 的 ， [UNK] 是 會 員 是 候 選 人 ， 這 就 是 他 的 工 作 ， 所 以 他 會 在 。 這 些 我 都 知 道 ， 我 也 以 為 我 已 經 100 % 依 賴 [UNK] ， 是 可 以 懂 他 只 是 為 了 讓 我 安 心 ， 告 訴 我 他 會 在 新 的 工 作 室 等 著 我 過 去 。 可 是 我 現 在 焦 慮 到 想 吐 [UNK] 既 昨 天 腰 痛 之 後 今 天 多 了 背 痛 ， 一 定 又 是 重 訓 的 過 程 中 姿 勢 錯 誤 導 致 的 ， 但 重 點 是 我 不 知 道 問 題 在 哪 裡 > < 和 現 在 的 教 練 上 課 已 經 超 過 半 年 ， 然 而 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 「 我 會 在 ， 你 放 心 。 我 們 就 慢 慢 把 環 境 適 應 。 」 治 療 的 最 後 ， [UNK] 說 著 ， 想 要 安 撫 我 下 週 工 作 室 搬 遷 的 焦 慮 。 當 下 覺 得 很 溫 暖 ， 很 放 心 地 微 笑 了 ， 可 是 我 現 在 卻 快 要 被 恐 懼 焦 慮 淹 沒 ， 因 為 [UNK] 也 給 過 我 太 多 承 諾 。 我 很 清 楚 [UNK] 和 [UNK] 是 截 然 不 同 的 ， [UNK] 是 會 員 是 候 選 人 ， 這 就 是 他 的 工 作 ， 所 以 他 會 在 。 這 些 我 都 知 道 ， 我 也 以 為 我 已 經 100 % 依 賴 [UNK] ， 是 可 以 懂 他 只 是 為 了 讓 我 安 心 ， 告 訴 我 他 會 在 新 的 工 作 室 等 著 我 過 去 。 可 是 我 現 在 焦 慮 到 想 吐 [UNK] 既 昨 天 腰 痛 之 後 今 天 多 了 背 痛 ， 一 定 又 是 重 訓 的 過 程 中 姿 勢 錯 誤 導 致 的 ， 但 重 點 是 我 不 知 道 問 題 在 哪 裡 > < 和 現 在 的 教 練 上 課 已 經 超 過 半 年 ， 然 而 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 519 2769 3298 1762 8024 872 3123 2552 511 2769 947 2218 2714 2714 2828 4472 1862 6900 2746 511 520 3780 4615 4638 3297 2527 8024 100 6303 5865 8024 2682 6206 2128 3062 2769 678 6867 2339 868 2147 3021 6907 4638 4193 2719 511 4534 678 6221 2533 2523 3984 3265 8024 2523 3123 2552 1765 2544 5010 749 8024 1377 3221 2769 4412 1762 1320 2571 6206 6158 2607 2758 4193 2719 3922 3760 8024 1728 4158 100 738 5183 6882 2769 1922 1914 2824 6330 511 2769 2523 3926 3504 100 1469 100 3221 2779 4197 679 1398 4638 8024 100 3221 3298 1519 3221 952 6908 782 8024 6857 2218 3221 800 4638 2339 868 8024 2792 809 800 3298 1762 511 6857 763 2769 6963 4761 6887 8024 2769 738 809 4158 2769 2347 5195 8135 110 898 6552 100 8024 3221 1377 809 2743 800 1372 3221 4158 749 6366 2769 2128 2552 8024 1440 6260 2769 800 3298 1762 3173 4638 2339 868 2147 5023 5865 2769 6882 1343 511 1377 3221 2769 4412 1762 4193 2719 1168 2682 1402 100 3188 3219 1921 5587 4578 722 2527 791 1921 1914 749 5520 4578 8024 671 2137 1348 3221 7028 6246 4638 6882 4923 704 2013 1248 7097 6299 2206 5636 4638 8024 852 7028 7953 3221 2769 679 4761 6887 1558 7539 1762 1525 6174 135 133 1469 4412 1762 4638 3136 5230 677 6307 2347 5195 6631 6882 1288 2399 8024 4197 5445 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 519 2769 3298 1762 8024 872 3123 2552 511 2769 947 2218 2714 2714 2828 4472 1862 6900 2746 511 520 3780 4615 4638 3297 2527 8024 100 6303 5865 8024 2682 6206 2128 3062 2769 678 6867 2339 868 2147 3021 6907 4638 4193 2719 511 4534 678 6221 2533 2523 3984 3265 8024 2523 3123 2552 1765 2544 5010 749 8024 1377 3221 2769 4412 1762 1320 2571 6206 6158 2607 2758 4193 2719 3922 3760 8024 1728 4158 100 738 5183 6882 2769 1922 1914 2824 6330 511 2769 2523 3926 3504 100 1469 100 3221 2779 4197 679 1398 4638 8024 100 3221 3298 1519 3221 952 6908 782 8024 6857 2218 3221 800 4638 2339 868 8024 2792 809 800 3298 1762 511 6857 763 2769 6963 4761 6887 8024 2769 738 809 4158 2769 2347 5195 8135 110 898 6552 100 8024 3221 1377 809 2743 800 1372 3221 4158 749 6366 2769 2128 2552 8024 1440 6260 2769 800 3298 1762 3173 4638 2339 868 2147 5023 5865 2769 6882 1343 511 1377 3221 2769 4412 1762 4193 2719 1168 2682 1402 100 3188 3219 1921 5587 4578 722 2527 791 1921 1914 749 5520 4578 8024 671 2137 1348 3221 7028 6246 4638 6882 4923 704 2013 1248 7097 6299 2206 5636 4638 8024 852 7028 7953 3221 2769 679 4761 6887 1558 7539 1762 1525 6174 135 133 1469 4412 1762 4638 3136 5230 677 6307 2347 5195 6631 6882 1288 2399 8024 4197 5445 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 其 實 我 也 不 知 道 在 焦 慮 甚 麼 也 許 是 不 想 有 人 來 管 吧 ? 本 來 是 社 區 自 聘 的 管 理 員 6 / 1 起 外 包 給 保 全 公 司 我 也 確 定 留 任 了 可 是 從 得 知 消 息 之 後 還 是 一 樣 焦 慮 今 天 去 保 全 公 司 面 談 ， 填 了 一 堆 不 知 道 是 甚 麼 的 資 料 （ 這 點 很 危 險 ， 好 孩 子 不 要 學 ） 因 為 還 有 另 一 個 同 事 不 知 為 何 早 到 ， 保 全 公 司 的 說 要 一 起 解 釋 ， 所 以 我 不 好 意 思 讓 他 等 其 實 事 後 也 沒 有 甚 麼 解 釋 ， 很 多 事 沒 搞 清 楚 其 實 就 制 度 面 來 說 ， 有 公 司 會 比 較 好 至 少 以 後 勞 健 保 有 著 落 了 以 後 上 班 時 間 相 對 固 定 ， 輪 班 不 像 現 在 這 樣 常 常 日 夜 顛 倒 而 且 工 作 地 點 沒 變 ， 服 務 對 象 沒 變 但 一 想 到 上 面 突 然 多 了 陌 生 人 來 管 就 覺 得 莫 名 害 怕 上 次 這 樣 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 其 實 我 也 不 知 道 在 焦 慮 甚 麼 也 許 是 不 想 有 人 來 管 吧 ? 本 來 是 社 區 自 聘 的 管 理 員 6 / 1 起 外 包 給 保 全 公 司 我 也 確 定 留 任 了 可 是 從 得 知 消 息 之 後 還 是 一 樣 焦 慮 今 天 去 保 全 公 司 面 談 ， 填 了 一 堆 不 知 道 是 甚 麼 的 資 料 （ 這 點 很 危 險 ， 好 孩 子 不 要 學 ） 因 為 還 有 另 一 個 同 事 不 知 為 何 早 到 ， 保 全 公 司 的 說 要 一 起 解 釋 ， 所 以 我 不 好 意 思 讓 他 等 其 實 事 後 也 沒 有 甚 麼 解 釋 ， 很 多 事 沒 搞 清 楚 其 實 就 制 度 面 來 說 ， 有 公 司 會 比 較 好 至 少 以 後 勞 健 保 有 著 落 了 以 後 上 班 時 間 相 對 固 定 ， 輪 班 不 像 現 在 這 樣 常 常 日 夜 顛 倒 而 且 工 作 地 點 沒 變 ， 服 務 對 象 沒 變 但 一 想 到 上 面 突 然 多 了 陌 生 人 來 管 就 覺 得 莫 名 害 怕 上 次 這 樣 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1071 2179 2769 738 679 4761 6887 1762 4193 2719 4493 7938 738 6258 3221 679 2682 3300 782 889 5052 1416 136 3315 889 3221 4852 1281 5632 5470 4638 5052 4415 1519 127 120 122 6629 1912 1259 5183 924 1059 1062 1385 2769 738 4825 2137 4522 818 749 1377 3221 2537 2533 4761 3867 2622 722 2527 6917 3221 671 3564 4193 2719 791 1921 1343 924 1059 1062 1385 7481 6312 8024 1856 749 671 1831 679 4761 6887 3221 4493 7938 4638 6536 3160 8020 6857 7953 2523 1314 7402 8024 1962 2111 2094 679 6206 2119 8021 1728 4158 6917 3300 1369 671 943 1398 752 679 4761 4158 862 3193 1168 8024 924 1059 1062 1385 4638 6303 6206 671 6629 6237 7026 8024 2792 809 2769 679 1962 2692 2590 6366 800 5023 1071 2179 752 2527 738 3760 3300 4493 7938 6237 7026 8024 2523 1914 752 3760 3018 3926 3504 1071 2179 2218 1169 2428 7481 889 6303 8024 3300 1062 1385 3298 3683 6733 1962 5635 2208 809 2527 1246 978 924 3300 5865 5862 749 809 2527 677 4408 3229 7279 4685 2205 1743 2137 8024 6743 4408 679 1008 4412 1762 6857 3564 2382 2382 3189 1915 7545 948 5445 684 2339 868 1765 7953 3760 6365 8024 3302 1243 2205 6496 3760 6365 852 671 2682 1168 677 7481 4960 4197 1914 749 7359 4495 782 889 5052 2218 6221 2533 5811 1399 2154 2586 677 3613 6857 3564 102\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1071 2179 2769 738 679 4761 6887 1762 4193 2719 4493 7938 738 6258 3221 679 2682 3300 782 889 5052 1416 136 3315 889 3221 4852 1281 5632 5470 4638 5052 4415 1519 127 120 122 6629 1912 1259 5183 924 1059 1062 1385 2769 738 4825 2137 4522 818 749 1377 3221 2537 2533 4761 3867 2622 722 2527 6917 3221 671 3564 4193 2719 791 1921 1343 924 1059 1062 1385 7481 6312 8024 1856 749 671 1831 679 4761 6887 3221 4493 7938 4638 6536 3160 8020 6857 7953 2523 1314 7402 8024 1962 2111 2094 679 6206 2119 8021 1728 4158 6917 3300 1369 671 943 1398 752 679 4761 4158 862 3193 1168 8024 924 1059 1062 1385 4638 6303 6206 671 6629 6237 7026 8024 2792 809 2769 679 1962 2692 2590 6366 800 5023 1071 2179 752 2527 738 3760 3300 4493 7938 6237 7026 8024 2523 1914 752 3760 3018 3926 3504 1071 2179 2218 1169 2428 7481 889 6303 8024 3300 1062 1385 3298 3683 6733 1962 5635 2208 809 2527 1246 978 924 3300 5865 5862 749 809 2527 677 4408 3229 7279 4685 2205 1743 2137 8024 6743 4408 679 1008 4412 1762 6857 3564 2382 2382 3189 1915 7545 948 5445 684 2339 868 1765 7953 3760 6365 8024 3302 1243 2205 6496 3760 6365 852 671 2682 1168 677 7481 4960 4197 1914 749 7359 4495 782 889 5052 2218 6221 2533 5811 1399 2154 2586 677 3613 6857 3564 102\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from model/model.ckpt-70\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from model/model.ckpt-70\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["##################################################\n","('- - - - - - - - - - - - - -附錄：【發文與推文罰則】- - - - - - - - - - - - - -第一條\\u3000凡未分類、自創分類、未滿20字（不含標點符號）之文章，\\u3000\\u3000\\u3000\\u3000含有自殺、自殘、OD相關內容，未在標題加註「有雷」或「雷」者，\\u3000\\u3000\\u3000\\u3000初犯者板主將直接刪除文章，不另外公告或通知。\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第二條\\u3000發文內容或推文大部分內容，違反中華民國法律者，\\u3000\\u3000\\u3000\\u3000初犯者板主將直接刪除文章並並水桶三日，不另外公告或通知。\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第三條\\u3000尋死文、自殺文、自殘文、OD文、藥物徵求買賣文等違規文章，\\u3000\\u3000\\u3000\\u3000除自殺文暫保留二日以便板友關心追蹤外，其餘文直接刪除並水桶三日。\\u3000\\u3000\\u3000\\u3000解除水桶之後其發文仍未遵循板規者，其發文劣退並水桶一個月。\\u3000\\u3000\\u3000\\u3000水桶後無論自行發文或在其他板友文章內推文再犯者皆永久水桶。第四條\\u3000本板對人身攻擊定義，不論是主動攻擊他人或因對他人言論不滿而回擊者，\\u3000\\u3000\\u3000\\u3000只要構成人身攻擊之事實，即視為違規，依程度輕重照板規懲處。\\u3000\\u3000\\u3000\\u3000此外，意見不合與人身攻擊間有很大的落差，\\u3000\\u3000\\u3000\\u3000請發文推文者勿因他人持反對意見，就任意指責對方人身攻擊，\\u3000\\u3000\\u3000\\u3000如經板主認定檢舉人有濫訴之嫌，得以不回應其檢舉。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000認定標準為：該字詞足以引起本板板友普遍性之不悅，並達到動怒的程度。\\u3000\\u3000\\u3000\\u3000例：「你根本不是憂鬱症吧！」、「會生病是你活該」等\\u3000\\u3000\\u3000\\u3000普通人身攻擊文劣退處理，並水桶一週；於推文中普通人身攻擊者水桶一週。\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000認定標準為：該字詞足以引起一般使用者普遍性之不悅，並達到動怒的程度。\\u3000\\u3000\\u3000\\u3000例：「你去死」、「吃屎吧你」等\\u3000\\u3000\\u3000\\u3000惡意人身攻擊文劣退處理，並水桶二週；於推文中惡意人身攻擊者水桶二週。\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶二個月。三犯永久水桶。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000認定標準為：可能觸犯刑法公然侮辱罪，含三字經、不雅形容詞等用詞。\\u3000\\u3000\\u3000\\u3000例：「幹」、「醜」、「賤」、「智障」、「白痴」、「腦殘」、「丁丁」等。\\u3000\\u3000\\u3000\\u3000公然侮辱罪需針對特定人士辱罵才能成立，用以上詞彙評論事件，\\u3000\\u3000\\u3000\\u3000或是該文章、推文中無法推斷出發表者有針對特定人物，不構成公然侮辱罪。\\u3000\\u3000\\u3000\\u3000但若有符合上述普通、惡意的人身攻擊標準，仍比照板規處理。\\u3000\\u3000\\u3000\\u3000違法人身攻擊文劣退並水桶一個月；於推文中違法人身攻擊者水桶一個月。\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶三個月。三犯永久水桶。\\u3000\\u3000\\u3000第五條\\u3000私人糾紛請私下處理，如對方已有騷擾之嫌，請至Violation板依規定檢舉。\\u3000\\u3000\\u3000\\u3000針對各種私人糾紛及狀況，本板採用以下規律進行處理：\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000板內糾紛之當事人於憂鬱板上發文或推文，且引起糾紛之雙方或多方，\\u3000\\u3000\\u3000\\u3000已在發文或推文中，出現人身攻擊、謾罵、挑釁、嘲諷、歧視等文字，\\u3000\\u3000\\u3000\\u3000板內糾紛文劣退處理並水桶一週；於推文中引發或回覆糾紛者水桶二週。\\u3000\\u3000\\u3000\\u3000其後發文仍未改善者，再劣退並水桶一個月；推文仍未改善者，水桶二個月。\\u3000\\u3000\\u3000\\u3000水桶後發文依然如故者水桶永久水桶、推文累犯超過一次者永久水桶。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000跨板糾紛指將其他板面之糾紛事務帶入本板發文或推文中並再次引發糾紛，\\u3000\\u3000\\u3000\\u3000造成本板混亂，且回推文已出現人身攻擊、謾罵、挑釁、嘲諷、歧視等文字；\\u3000\\u3000\\u3000\\u3000跨板糾紛文劣退處理並水桶二週；於推文中引發或回覆糾紛者水桶一個月\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u30001.若該私人糾紛已造成大量板友之不悅，甚至影響到板友情緒或加重病情時，\\u3000\\u3000\\u3000\\u3000\\u3000只要有超過15人公開以回推文表示受到影響，超過2人依規定向板主檢舉，\\u3000\\u3000\\u3000\\u3000\\u3000不論原文文章內容，或被指名之使用者推文內容是否達到違規程度，\\u3000\\u3000\\u3000\\u3000\\u3000該發文／推文者即被認定為在憂鬱版鬧板的使用者，改以鬧板文處置。\\u3000\\u3000\\u3000\\u3000\\u3000且依情節嚴重程度懲處，必要時板主有權發起投票裁決。\\u3000\\u3000\\u3000\\u30002.若私人糾紛之當事人，或其它回文推文參與討論之板友，\\u3000\\u3000\\u3000\\u3000\\u3000因該糾紛遭懲處後，直接在板面上向板主及板友放話，\\u3000\\u3000\\u3000\\u3000\\u3000或以站內信、水球等方式，向板主挑釁，揚言將於本板板面，\\u3000\\u3000\\u3000\\u3000\\u3000以任何形式擴大紛爭，或欲報復與其意見不合者，\\u3000\\u3000\\u3000\\u3000\\u3000直接視為蓄意破壞板面秩序之惡意鬧板者，永久水桶。\\u3000\\u3000\\u3000\\u3000\\u3000必要時，板主得將相關站內信、水球，做為板務溝通證據，\\u3000\\u3000\\u3000\\u3000\\u3000呈送給本組小組長，以特殊案件處理。\\u3000\\u3000\\u3000\\u30003.另為顧慮以多重ID持有者蓄意鑽取本規定漏洞，\\u3000\\u3000\\u3000\\u3000\\u3000若是使用多重ID發表私人糾紛類型文，經站務相關方面查證後，\\u3000\\u3000\\u3000\\u3000\\u3000不論糾紛文造成的傷害程度輕重，該使用者及其多重ID均永久水桶。\\u3000\\u3000\\u3000\\u3000\\u3000若因浮動ip造成無法判定該id是否為分身id者，該id暫處水桶，\\u3000\\u3000\\u3000\\u3000\\u3000且待板主群於群組板申請多重ID移送ID_Multi後，\\u3000\\u3000\\u3000\\u3000\\u3000由PTT站方判定是否為多重ID再解除水桶並依照憂鬱板板規處理。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u30001.私人糾紛之當事人於板面上發文或推文，\\u3000\\u3000\\u3000\\u3000\\u3000但引起糾紛者尚能維持理性和平之討論，未發生違反板規情事。\\u3000\\u3000\\u3000\\u30002.該糾紛雖已有其它非當事人加入討論，但參與者僅是提出解決糾紛之建議，\\u3000\\u3000\\u3000\\u3000\\u3000並未進一步擴大糾紛，討論串中也未出現違規情結者。：第六條\\u3000鬧板文劣退處理，於推文中鬧板者水桶一週；\\u3000\\u3000\\u3000\\u3000其後發文或推文仍未改善者劣退水桶一個月。三犯永久水桶。第七條\\u3000注音文將直接刪除文章並退回發文者信箱，不事先警告，也不另行公告。\\u3000\\u3000\\u3000\\u3000其後發文仍未改善者再刪文，並視為不尊重板規、水桶一個月。\\u3000\\u3000\\u3000\\u3000累犯超過三次者，劣退處理；劣退後依然如故者，永久水桶。第七條\\u3000非公益形態、能造成他人利益之廣告文直接劣退，外加永久水桶。第八條\\u3000誤用板主專用分類標題[公告]者，一律視為惡意鬧板，永久水桶。- - - - - - - - - - - 附錄：【違規文章及違規推文說明】- - - - - - - - - - - -\\u3000\\u3000１、廣告文：文章內容或推文有廣告嫌疑，或該文明顯可增加發文者利益者均屬廣告文。２、自殺文：文章內容或推文與自殺有關者，含自殺方法討論、慫恿他人自殺。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000勸導板友勿自殺者，或純粹討論生死意義者不在此限。３、尋死文：文章內容或推文有尋死意圖者，如出現「我要死」、「我要跳樓」等文字，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000有尋死之想法而向板友求助者，討論如何解決尋死意圖者不在此限。４、藥物文：文章內容或推文中徵求、買賣藥物或提供、詢問非正當藥物取得方法等等。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000各項藥物問題請詢問醫生，並遵照醫囑服用藥物。５、ＯＤ文：文章內容或推文與OD有關者。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000對OD行為感到後悔，勸導板友勿OD者不在此限；\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000但嚴禁在文章中提及OD的藥品名稱及數量，違者依OD文處置。６、自殘文：文章內容或推文與自殘有關者，含自殘意圖、自殘討論、自殘感想。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000對自殘行為感到後悔，勸導板友勿自殘者不在此限。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000但嚴禁在文章中詳述或提及詳細的自殘方法及過程，違者依自殘文處置。７、攻擊文：文章內容或推文中公佈私人資料或各類型人身攻擊等等。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000於推文中人身攻擊者，有指名則視為攻擊被指名之對象，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000未指名者則視為攻擊該文章作者。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000板友發洩情緒並無不可，但請將相關人物名稱與不雅文字做隱藏處理，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000並請避免使用具有污辱性之詞句，以免觸犯法律。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000本板將人身攻擊分為「普通」、「惡意」、「違法」等三種程度，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000依嚴重程度不同，有不同等級的懲處，請詳見本板規之罰則內容。８、鬧板文：除版主能及時認定為刻意洗版、鬧版的文章之外，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000若有文章或推文造成大量板友之不悅，甚至影響到板友情緒或加重病情時，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000只要有超過15人公開以回推文表示受到影響，超過2人依規定向板主檢舉，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000不論原文文章內容，或被指名之使用者推文內容是否達到違規程度，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000該發文／推文者即被認定為在憂鬱版鬧板的使用者，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000將依情節嚴重程度懲處，必要時板主有權發起投票裁決。\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000９、注音文：文章內容有注音符號者，例：我ㄉ、好ㄇ、ㄍㄍ等，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000或文章內容中有火星文者，例：可ｉ、泥棉等皆算注音火星文；\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000若有無法以中文表達的音，如ㄍㄧㄥ、ㄎㄎ等，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000或必須以諧音字表達的字詞，如：逼埃、撒比速等，\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000以上比較特殊的狀況不在此限。--如果因為我的言論而對prozac版產生恐懼的朋友 先跟你們說對不起我身為一個邊緣性人格障礙的患者 總是常常會不由自主的歇斯底里起來請原諒我的措辭太過於嚴厲/偏激/惡霸/兇殘..(請自行帶入任何負面字眼)但是請記得我的名字 因為我好喜歡我是Prozac版最愛罵人的雞巴版主     --', array([-0.12526642, -2.220108  , -4.695005  ], dtype=float32), 0, 'low')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IM-Lyzk08ke7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731759443,"user_tz":-480,"elapsed":846,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"3d339b77-d875-4edb-e482-4924e1e76883"},"source":["results = [tr[2] for tr in test_results]\n","print(results)\n","# save the result back to the csv file\n","test_data_df['Predicted'] = results\n","test_data_df.to_csv('data/test_data_result.csv', encoding='utf8')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gT-xGf_6jbAC"},"source":["## Predict single input here"]},{"cell_type":"code","metadata":{"id":"TgOLEMXvjbwP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731873120,"user_tz":-480,"elapsed":10890,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"eee8c814-b60d-471a-caae-13baae04cbd0"},"source":["#Classifying random sentences\n","test_results = getPrediction(['其實我本來就不太想活了每次和媽媽說完話我就開始辜狗自殺方法',\n","                       '帶了很多藥來就是因為怕這樣的時刻又出現這才是真正的逢魔時刻吧想自我毀滅盡量躺著保持安靜再撐幾天就回家了沒事的',\n","                       '還有半小時覺得倦怠低落負面而自我放逐下班要吃冰冰彷彿是每天的救贖潰瘍還沒好',\n","                       '群組裡面都是很負面的話受不了就不要加入下輩子再見也可以說不定會好 '\n","                       ])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 4\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 4\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 其 實 我 本 來 就 不 太 想 活 了 每 次 和 媽 媽 說 完 話 我 就 開 始 辜 狗 自 殺 方 法 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 其 實 我 本 來 就 不 太 想 活 了 每 次 和 媽 媽 說 完 話 我 就 開 始 辜 狗 自 殺 方 法 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1071 2179 2769 3315 889 2218 679 1922 2682 3833 749 3680 3613 1469 2061 2061 6303 2130 6282 2769 2218 7274 1993 6790 4318 5632 3669 3175 3791 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 1071 2179 2769 3315 889 2218 679 1922 2682 3833 749 3680 3613 1469 2061 2061 6303 2130 6282 2769 2218 7274 1993 6790 4318 5632 3669 3175 3791 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 帶 了 很 多 藥 來 就 是 因 為 怕 這 樣 的 時 刻 又 出 現 這 才 是 真 正 的 逢 魔 時 刻 吧 想 自 我 毀 滅 盡 量 躺 著 保 持 安 靜 再 撐 幾 天 就 回 家 了 沒 事 的 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 帶 了 很 多 藥 來 就 是 因 為 怕 這 樣 的 時 刻 又 出 現 這 才 是 真 正 的 逢 魔 時 刻 吧 想 自 我 毀 滅 盡 量 躺 著 保 持 安 靜 再 撐 幾 天 就 回 家 了 沒 事 的 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2380 749 2523 1914 5973 889 2218 3221 1728 4158 2586 6857 3564 4638 3229 1174 1348 1139 4412 6857 2798 3221 4696 3633 4638 6864 7795 3229 1174 1416 2682 5632 2769 3672 3994 4674 7030 6720 5865 924 2898 2128 7477 1086 3052 2407 1921 2218 1726 2157 749 3760 752 4638 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 2380 749 2523 1914 5973 889 2218 3221 1728 4158 2586 6857 3564 4638 3229 1174 1348 1139 4412 6857 2798 3221 4696 3633 4638 6864 7795 3229 1174 1416 2682 5632 2769 3672 3994 4674 7030 6720 5865 924 2898 2128 7477 1086 3052 2407 1921 2218 1726 2157 749 3760 752 4638 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 還 有 半 小 時 覺 得 倦 怠 低 落 負 面 而 自 我 放 逐 下 班 要 吃 冰 冰 彷 彿 是 每 天 的 救 贖 潰 瘍 還 沒 好 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 還 有 半 小 時 覺 得 倦 怠 低 落 負 面 而 自 我 放 逐 下 班 要 吃 冰 冰 彷 彿 是 每 天 的 救 贖 潰 瘍 還 沒 好 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 6917 3300 1288 2207 3229 6221 2533 958 2591 856 5862 6511 7481 5445 5632 2769 3123 6852 678 4408 6206 1391 1102 1102 2513 2517 3221 3680 1921 4638 3131 6562 4061 4598 6917 3760 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 6917 3300 1288 2207 3229 6221 2533 958 2591 856 5862 6511 7481 5445 5632 2769 3123 6852 678 4408 6206 1391 1102 1102 2513 2517 3221 3680 1921 4638 3131 6562 4061 4598 6917 3760 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 群 組 裡 面 都 是 很 負 面 的 話 受 不 了 就 不 要 加 入 下 輩 子 再 見 也 可 以 說 不 定 會 好 [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 群 組 裡 面 都 是 很 負 面 的 話 受 不 了 就 不 要 加 入 下 輩 子 再 見 也 可 以 說 不 定 會 好 [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5408 5175 6174 7481 6963 3221 2523 6511 7481 4638 6282 1358 679 749 2218 679 6206 1217 1057 678 6742 2094 1086 6210 738 1377 809 6303 679 2137 3298 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 5408 5175 6174 7481 6963 3221 2523 6511 7481 4638 6282 1358 679 749 2218 679 6206 1217 1057 678 6742 2094 1086 6210 738 1377 809 6303 679 2137 3298 1962 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from model/model.ckpt-70\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from model/model.ckpt-70\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vb6t1nhijfr1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731874292,"user_tz":-480,"elapsed":1168,"user":{"displayName":"Jeremy Lai","photoUrl":"","userId":"02259994175981005007"}},"outputId":"bb9025e6-ad95-4453-b680-b5e502ced5e9"},"source":["test_results"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('其實我本來就不太想活了每次和媽媽說完話我就開始辜狗自殺方法',\n","  array([-3.9395003 , -0.02154459, -6.289239  ], dtype=float32),\n","  1,\n","  'high'),\n"," ('帶了很多藥來就是因為怕這樣的時刻又出現這才是真正的逢魔時刻吧想自我毀滅盡量躺著保持安靜再撐幾天就回家了沒事的',\n","  array([-4.360148  , -0.01549961, -5.9508667 ], dtype=float32),\n","  1,\n","  'high'),\n"," ('還有半小時覺得倦怠低落負面而自我放逐下班要吃冰冰彷彿是每天的救贖潰瘍還沒好',\n","  array([-3.9878404 , -0.02051002, -6.3416457 ], dtype=float32),\n","  1,\n","  'high'),\n"," ('群組裡面都是很負面的話受不了就不要加入下輩子再見也可以說不定會好 ',\n","  array([-1.7387948 , -0.19585973, -6.1467667 ], dtype=float32),\n","  1,\n","  'high')]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"J4GO0fA5joQK"},"source":["Reference: https://analyticsindiamag.com/step-by-step-guide-to-implement-multi-class-classification-with-bert-tensorflow/"]}]}